{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c82b44e-b020-42fd-b26b-48ff1eb137ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "311725b5-79aa-4094-b2c7-92cfee46c44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of data points: 4921\n",
      "The number of retained data points: 3462 (70.35%)\n"
     ]
    }
   ],
   "source": [
    "def validate_gpt_json(data):\n",
    "    try: \n",
    "        evaluation_of_student_response = data.get(\"Evaluation of Student Response\")\n",
    "        action_based_on_evaluation = data.get(\"Action Based on Evaluation\")\n",
    "        subproblem_state = data.get(\"Subproblem State\")\n",
    "        subproblem = data.get(\"Subproblem\")\n",
    "        tutorbot = data.get(\"Tutorbot\")\n",
    "        \n",
    "        if (\n",
    "            isinstance(evaluation_of_student_response, str) and len(evaluation_of_student_response) == 1 and \n",
    "            isinstance(action_based_on_evaluation, str) and len(action_based_on_evaluation) <= 2 and \n",
    "            isinstance(subproblem_state, str) and len(subproblem_state) == 1 and \n",
    "            isinstance(subproblem, str) and \n",
    "            isinstance(tutorbot, str)\n",
    "        ):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except json.JSONDecodeError:\n",
    "        return False\n",
    "\n",
    "def validate_spock_json(data):\n",
    "    try:\n",
    "        if \"Action Based on Evaluation\" not in data or \\\n",
    "            \"Evaluation of Student Response\" not in data or \\\n",
    "            \"Subproblem State\" not in data or \\\n",
    "            \"Subproblem\" not in data or \\\n",
    "            \"Tutorbot\" not in data:\n",
    "            return False\n",
    "\n",
    "        if data[\"Action Based on Evaluation\"] == \"\" and \\\n",
    "            data[\"Evaluation of Student Response\"] == \"\" and \\\n",
    "            data[\"Subproblem State\"] == \"\" and \\\n",
    "            data[\"Subproblem\"] == \"\" and \\\n",
    "            data[\"Tutorbot\"] == \"\":\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def format_dpo_dataset(response_file):\n",
    "    dpo_dataset = {\n",
    "        \"prompt\":[],\n",
    "        \"chosen\":[],\n",
    "        \"rejected\":[]\n",
    "    }\n",
    "\n",
    "    retained = 0\n",
    "    total = 0\n",
    "    \n",
    "    with open(response_file, 'r') as file:\n",
    "        reader = csv.reader(file) # ['prompt', 'response', 'gpt']\n",
    "        next(reader)\n",
    "\n",
    "        for row in reader:\n",
    "            total += 1\n",
    "            \n",
    "            prompt = row[0]\n",
    "            tutorbot = row[1]\n",
    "            gpt = row[2]\n",
    "\n",
    "            # Choose good gpt responses\n",
    "            gpt = ast.literal_eval(gpt)\n",
    "            if validate_gpt_json(gpt) == False:\n",
    "                continue\n",
    "                \n",
    "            # Skip corrupted tutorbot responses\n",
    "            try:\n",
    "                tutorbot = ast.literal_eval(tutorbot)\n",
    "            except:\n",
    "                dpo_dataset[\"prompt\"].append(prompt)\n",
    "                dpo_dataset[\"chosen\"].append(str(gpt))\n",
    "                dpo_dataset[\"rejected\"].append(tutorbot)\n",
    "                retained += 1\n",
    "                continue\n",
    "                \n",
    "            if validate_spock_json(tutorbot) == False:\n",
    "                dpo_dataset[\"prompt\"].append(prompt)\n",
    "                dpo_dataset[\"chosen\"].append(str(gpt))\n",
    "                dpo_dataset[\"rejected\"].append(str(tutorbot)) \n",
    "                retained += 1\n",
    "                continue\n",
    "\n",
    "            # Add the data point\n",
    "            gpt_eval = gpt[\"Evaluation of Student Response\"].strip()\n",
    "            tutorbot_eval = tutorbot[\"Evaluation of Student Response\"].strip()\n",
    "\n",
    "            if gpt_eval != tutorbot_eval:\n",
    "                dpo_dataset[\"prompt\"].append(prompt)\n",
    "                dpo_dataset[\"chosen\"].append(str(gpt))\n",
    "                dpo_dataset[\"rejected\"].append(str(tutorbot))\n",
    "                retained += 1\n",
    "                continue\n",
    "            \n",
    "            gpt_action = gpt[\"Action Based on Evaluation\"].strip()\n",
    "            tutorbot_action = tutorbot[\"Action Based on Evaluation\"].strip()\n",
    "\n",
    "            if gpt_action != tutorbot_action:\n",
    "                dpo_dataset[\"prompt\"].append(prompt)\n",
    "                dpo_dataset[\"chosen\"].append(str(gpt))\n",
    "                dpo_dataset[\"rejected\"].append(str(tutorbot))\n",
    "                retained += 1\n",
    "                continue\n",
    "\n",
    "            gpt_sub_state = gpt[\"Subproblem State\"].strip()\n",
    "            tutorbot_sub_state = tutorbot[\"Subproblem State\"].strip()\n",
    "\n",
    "            if gpt_sub_state != tutorbot_sub_state:\n",
    "                dpo_dataset[\"prompt\"].append(prompt)\n",
    "                dpo_dataset[\"chosen\"].append(str(gpt))\n",
    "                dpo_dataset[\"rejected\"].append(str(tutorbot))\n",
    "                retained += 1\n",
    "                continue\n",
    "                \n",
    "    print(\"The total number of data points:\", total)\n",
    "    print(\"The number of retained data points:\", retained, f\"({retained / total * 100:.2f}%)\")\n",
    "    \n",
    "    return dpo_dataset\n",
    "\n",
    "def store(data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "\n",
    "######################################\n",
    "# Change these paths\n",
    "response_file = \"/data/kn22/spock_bio/spock_bio_Mistral-7B-Instruct-v0.2_r1/final_checkpoint-dpo/responses.csv\"\n",
    "data_file = \"/data/kn22/dpo_data/bio/dpo_train/Mistral-7B-Instruct-v0.2_r1_dpo_bio_uniform_batch_123_filtered_dpo-both.json\"\n",
    "######################################\n",
    "\n",
    "dpo_dataset = format_dpo_dataset(response_file)\n",
    "\n",
    "store(dpo_dataset, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "655af9b7-08df-45d1-ad61-aacd0ce60875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of data points: 4921\n",
      "The number of retained data points: 1379 (28.02%)\n"
     ]
    }
   ],
   "source": [
    "# def validate_gpt_json(data):\n",
    "#     try: \n",
    "#         evaluation_of_student_response = data.get(\"Evaluation of Student Response\")\n",
    "#         action_based_on_evaluation = data.get(\"Action Based on Evaluation\")\n",
    "#         subproblem_state = data.get(\"Subproblem State\")\n",
    "#         tutorbot = data.get(\"Tutorbot\")\n",
    "        \n",
    "#         if (\n",
    "#             isinstance(evaluation_of_student_response, str) and len(evaluation_of_student_response) == 1 and \n",
    "#             isinstance(action_based_on_evaluation, str) and len(action_based_on_evaluation) <= 2 and \n",
    "#             isinstance(subproblem_state, str) and len(subproblem_state) == 1 and \n",
    "#             isinstance(tutorbot, str)\n",
    "#         ):\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "#     except json.JSONDecodeError:\n",
    "#         return False\n",
    "\n",
    "# def validate_spock_json(data):\n",
    "#     try:\n",
    "#         if \"Action Based on Evaluation\" not in data or \\\n",
    "#             \"Evaluation of Student Response\" not in data or \\\n",
    "#             \"Subproblem State\" not in data or \\\n",
    "#             \"Tutorbot\" not in data:\n",
    "#             return False\n",
    "\n",
    "#         if data[\"Action Based on Evaluation\"] == \"\" and \\\n",
    "#             data[\"Evaluation of Student Response\"] == \"\" and \\\n",
    "#             data[\"Subproblem State\"] == \"\" and \\\n",
    "#             data[\"Tutorbot\"] == \"\":\n",
    "#             return False\n",
    "            \n",
    "#         return True\n",
    "#     except:\n",
    "#         return False\n",
    "    \n",
    "# def format_dpo_dataset(response_file):\n",
    "#     dpo_dataset = {\n",
    "#         \"prompt\":[],\n",
    "#         \"chosen\":[],\n",
    "#         \"rejected\":[]\n",
    "#     }\n",
    "\n",
    "#     retained = 0\n",
    "#     total = 0\n",
    "    \n",
    "#     with open(response_file, 'r') as file:\n",
    "#         reader = csv.reader(file) # ['prompt', 'response', 'gpt']\n",
    "#         next(reader)\n",
    "\n",
    "#         for row in reader:\n",
    "#             total += 1\n",
    "            \n",
    "#             prompt = row[0]\n",
    "#             tutorbot = row[1]\n",
    "#             gpt = row[2]\n",
    "            \n",
    "#             # Skip corrupted tutorbot responses\n",
    "#             try:\n",
    "#                 tutorbot = ast.literal_eval(tutorbot)\n",
    "#             except:\n",
    "#                 continue\n",
    "                \n",
    "#             if validate_spock_json(tutorbot) == False:\n",
    "#                 continue\n",
    "\n",
    "#             # Choose good gpt responses\n",
    "#             gpt = ast.literal_eval(gpt)\n",
    "#             if validate_gpt_json(gpt) == False:\n",
    "#                 continue\n",
    "\n",
    "#             # Add the data point\n",
    "#             gpt_eval = gpt[\"Evaluation of Student Response\"].strip()\n",
    "#             tutorbot_eval = tutorbot[\"Evaluation of Student Response\"].strip()\n",
    "\n",
    "#             if gpt_eval != tutorbot_eval:\n",
    "#                 dpo_dataset[\"prompt\"].append(prompt)\n",
    "#                 dpo_dataset[\"chosen\"].append(str(gpt))\n",
    "#                 dpo_dataset[\"rejected\"].append(str(tutorbot))\n",
    "#                 retained += 1\n",
    "#                 continue\n",
    "            \n",
    "#             gpt_action = gpt[\"Action Based on Evaluation\"].strip()\n",
    "#             tutorbot_action = tutorbot[\"Action Based on Evaluation\"].strip()\n",
    "\n",
    "#             if gpt_action != tutorbot_action:\n",
    "#                 dpo_dataset[\"prompt\"].append(prompt)\n",
    "#                 dpo_dataset[\"chosen\"].append(str(gpt))\n",
    "#                 dpo_dataset[\"rejected\"].append(str(tutorbot))\n",
    "#                 retained += 1\n",
    "#                 continue\n",
    "\n",
    "#             gpt_sub_state = gpt[\"Subproblem State\"].strip()\n",
    "#             tutorbot_sub_state = tutorbot[\"Subproblem State\"].strip()\n",
    "\n",
    "#             if gpt_sub_state != tutorbot_sub_state:\n",
    "#                 dpo_dataset[\"prompt\"].append(prompt)\n",
    "#                 dpo_dataset[\"chosen\"].append(str(gpt))\n",
    "#                 dpo_dataset[\"rejected\"].append(str(tutorbot))\n",
    "#                 retained += 1\n",
    "#                 continue\n",
    "                \n",
    "#     print(\"The total number of data points:\", total)\n",
    "#     print(\"The number of retained data points:\", retained, f\"({retained / total * 100:.2f}%)\")\n",
    "    \n",
    "#     return dpo_dataset\n",
    "\n",
    "# def store(data, file_path):\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         json.dump(data, file)\n",
    "\n",
    "\n",
    "# ######################################\n",
    "# # Change these paths\n",
    "# response_file = \"/data/kn22/spock_bio/spock_bio_mistral-instruct_r3/final_checkpoint-dpo/responses.csv\"\n",
    "# data_file = \"/data/kn22/dpo_data/bio/dpo_train/mistral-instruct_dpo_bio_uniform_batch_123_filtered_dpo.json\"\n",
    "# ######################################\n",
    "\n",
    "# dpo_dataset = format_dpo_dataset(response_file)\n",
    "\n",
    "# store(dpo_dataset, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "634f5a77-ade8-4396-adc2-aa64a218f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of data points: 4921\n",
      "The number of retained data points: 4921 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# def validate_gpt_json(data):\n",
    "#     try: \n",
    "#         evaluation_of_student_response = data.get(\"Evaluation of Student Response\")\n",
    "#         action_based_on_evaluation = data.get(\"Action Based on Evaluation\")\n",
    "#         subproblem_state = data.get(\"Subproblem State\")\n",
    "#         subproblem = data.get(\"Subproblem\")\n",
    "#         tutorbot = data.get(\"Tutorbot\")\n",
    "        \n",
    "#         if (\n",
    "#             isinstance(evaluation_of_student_response, str) and len(evaluation_of_student_response) == 1 and \n",
    "#             isinstance(action_based_on_evaluation, str) and len(action_based_on_evaluation) <= 2 and \n",
    "#             isinstance(subproblem_state, str) and len(subproblem_state) == 1 and \n",
    "#             isinstance(subproblem, str) and \n",
    "#             isinstance(tutorbot, str)\n",
    "#         ):\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "#     except json.JSONDecodeError:\n",
    "#         return False\n",
    "\n",
    "# def validate_spock_json(data):\n",
    "#     return True\n",
    "    \n",
    "# def format_dpo_dataset(response_file):\n",
    "#     dpo_dataset = {\n",
    "#         \"prompt\":[],\n",
    "#         \"chosen\":[],\n",
    "#         \"rejected\":[]\n",
    "#     }\n",
    "\n",
    "#     retained = 0\n",
    "#     total = 0\n",
    "    \n",
    "#     with open(response_file, 'r') as file:\n",
    "#         reader = csv.reader(file) # ['prompt', 'response', 'gpt']\n",
    "#         next(reader)\n",
    "\n",
    "#         for row in reader:\n",
    "#             total += 1\n",
    "            \n",
    "#             prompt = row[0]\n",
    "#             tutorbot = row[1]\n",
    "#             gpt = row[2]\n",
    "  \n",
    "#             gpt = ast.literal_eval(gpt)\n",
    "#             if validate_gpt_json(gpt) == False:\n",
    "#                 continue\n",
    "\n",
    "#             gpt = str(gpt)\n",
    "\n",
    "#             retained += 1\n",
    "#             dpo_dataset[\"prompt\"].append(prompt)\n",
    "#             dpo_dataset[\"chosen\"].append(gpt)\n",
    "#             dpo_dataset[\"rejected\"].append(tutorbot)\n",
    "                \n",
    "#     print(\"The total number of data points:\", total)\n",
    "#     print(\"The number of retained data points:\", retained, f\"({retained / total * 100:.2f}%)\")\n",
    "    \n",
    "#     return dpo_dataset\n",
    "\n",
    "# def store(data, file_path):\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         json.dump(data, file)\n",
    "\n",
    "\n",
    "# ######################################\n",
    "# # Change these paths\n",
    "# response_file = \"/data/kn22/spock_bio/spock_bio_vicuna-7b-v1.5_r1/final_checkpoint-dpo/responses.csv\"\n",
    "# data_file = \"/data/kn22/dpo_data/bio/dpo_train/vicuna-7b-v1.5_r1_dpo_bio_uniform_batch_123_filtered_dpo-all.json\"\n",
    "# ######################################\n",
    "\n",
    "# dpo_dataset = format_dpo_dataset(response_file)\n",
    "\n",
    "# store(dpo_dataset, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c6149fbc-19f8-4924-afd0-44c287295fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'Evaluation of Student Response': 'b', 'Action Based on Evaluation': '3', 'Subproblem State': 'z', 'Subproblem': '', 'Tutorbot': 'Great job! Your answer covers all the necessary points regarding the sequence of light traveling through the eye, the roles of each component, and the changes that occur along the way. Keep up the good work!'}\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_dataset[\"rejected\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7f4814e0-e266-4b12-82e7-40e4b3dfd29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'Evaluation of Student Response\\': \\'b\\', \\'Action Based on Evaluation\\': \\'3\\', \\'Subproblem State\\': \\'z\\', \\'Subproblem\\': \\'3. Changes that occur to light as it goes through each stage.\\', \\'Tutorbot\\': \"Great job! You\\'ve accurately described the changes that occur to light as it goes through each stage of the eye. You\\'ve completed all the subproblems, and the main problem is now finished.\"}'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_dataset[\"chosen\"][-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
